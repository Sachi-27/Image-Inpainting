2023-11-17 13:39:27,752 INFO Arguments: Namespace(config='configs/config.yaml', seed=None)
2023-11-17 13:39:27,752 INFO Random seed: 5114
2023-11-17 13:39:27,753 INFO Configuration: {'dataset_name': 'animals', 'data_with_subfolder': False, 'train_data_path': '../animals_train', 'val_data_path': '../animals_test', 'resume': None, 'batch_size': 32, 'image_shape': [256, 256, 3], 'mask_shape': [128, 128], 'mask_batch_same': True, 'max_delta_shape': [32, 32], 'margin': [0, 0], 'discounted_mask': True, 'spatial_discounting_gamma': 0.9, 'random_crop': False, 'mask_type': 'hole', 'mosaic_unit_size': 12, 'expname': 'benchmark', 'cuda': True, 'gpu_ids': [0, 1, 2, 3, 4], 'num_workers': 5, 'lr': 0.0001, 'beta1': 0.5, 'beta2': 0.9, 'n_critic': 1, 'niter': 300, 'print_iter': 1, 'viz_iter': 10, 'viz_max_out': 12, 'snapshot_save_iter': 10, 'coarse_l1_alpha': 1.2, 'l1_loss_alpha': 1.2, 'ae_loss_alpha': 1.2, 'global_wgan_loss_alpha': 1.0, 'gan_loss_alpha': 0.001, 'wgan_gp_lambda': 10, 'netG': {'input_dim': 3, 'ngf': 32}, 'netD': {'input_dim': 3, 'ndf': 64}}
2023-11-17 13:39:27,753 INFO Training on dataset: animals
2023-11-17 13:39:31,851 INFO 
Generator_primitive(
  (coarse_generator): CoarseGenerator(
    (conv1): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(5, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (conv2_downsample): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (conv3): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv4_downsample): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (conv5): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv6): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv7_atrous): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
    )
    (conv8_atrous): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
    )
    (conv9_atrous): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))
    )
    (conv10_atrous): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16))
    )
    (conv11): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv12): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv13): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv14): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv15): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv16): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv17): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (conv): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (fine_generator): CoarseGenerator(
    (conv1): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(5, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    )
    (conv2_downsample): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (conv3): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv4_downsample): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (conv5): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv6): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv7_atrous): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
    )
    (conv8_atrous): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))
    )
    (conv9_atrous): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))
    )
    (conv10_atrous): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16))
    )
    (conv11): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv12): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv13): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv14): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv15): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv16): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): ELU(alpha=1.0, inplace=True)
      (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (conv17): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (conv): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
)
2023-11-17 13:39:31,852 INFO 
LocalDis(
  (dis_conv_module): DisConvModule(
    (conv1): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv2): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv3): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv4): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
  )
  (linear): Linear(in_features=16384, out_features=1, bias=True)
)
2023-11-17 13:39:31,852 INFO 
GlobalDis(
  (dis_conv_module): DisConvModule(
    (conv1): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv2): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv3): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
    (conv4): Conv2dBlock(
      (pad): ZeroPad2d(padding=(0, 0, 0, 0), value=0.0)
      (activation): LeakyReLU(negative_slope=0.2, inplace=True)
      (conv): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
    )
  )
  (linear): Linear(in_features=65536, out_features=1, bias=True)
)
2023-11-17 13:47:02,843 INFO Iter: [1/300] l1: 0.093558 ae: 0.521269 wgan_g: -184.528412 wgan_d: -9.771249 wgan_gp: 0.876959 g: 0.553264 d: -1.001662 speed: 0.00 batches/s 
2023-11-17 13:54:06,197 INFO Iter: [2/300] l1: 0.086540 ae: 0.395509 wgan_g: -221.363892 wgan_d: -31.912077 wgan_gp: 0.805185 g: 0.357095 d: -23.860231 speed: 0.00 batches/s 
2023-11-17 14:01:09,484 INFO Iter: [3/300] l1: 0.081241 ae: 0.342317 wgan_g: -223.594299 wgan_d: -23.384459 wgan_gp: 0.551637 g: 0.284675 d: -17.868086 speed: 0.00 batches/s 
2023-11-17 14:08:12,649 INFO Iter: [4/300] l1: 0.079036 ae: 0.307417 wgan_g: -166.049484 wgan_d: -17.137150 wgan_gp: 0.412968 g: 0.297695 d: -13.007466 speed: 0.00 batches/s 
2023-11-17 14:15:17,294 INFO Iter: [5/300] l1: 0.075747 ae: 0.279395 wgan_g: -164.722580 wgan_d: -11.290769 wgan_gp: 0.304652 g: 0.261449 d: -8.244246 speed: 0.00 batches/s 
2023-11-17 14:22:22,102 INFO Iter: [6/300] l1: 0.072937 ae: 0.251709 wgan_g: -161.226212 wgan_d: -6.741697 wgan_gp: 0.126316 g: 0.228349 d: -5.478539 speed: 0.00 batches/s 
2023-11-17 14:29:32,800 INFO Iter: [7/300] l1: 0.069981 ae: 0.235423 wgan_g: -136.224792 wgan_d: -9.039196 wgan_gp: 0.143828 g: 0.230260 d: -7.600917 speed: 0.00 batches/s 
2023-11-17 14:36:37,181 INFO Iter: [8/300] l1: 0.067562 ae: 0.223847 wgan_g: -118.122467 wgan_d: -12.160879 wgan_gp: 0.219776 g: 0.231569 d: -9.963118 speed: 0.00 batches/s 
2023-11-17 14:43:42,567 INFO Iter: [9/300] l1: 0.066051 ae: 0.215345 wgan_g: -123.309227 wgan_d: -11.917920 wgan_gp: 0.222012 g: 0.214366 d: -9.697797 speed: 0.00 batches/s 
2023-11-17 14:49:20,785 INFO Iter: [10/300] l1: 0.064188 ae: 0.208335 wgan_g: -95.763443 wgan_d: -12.481069 wgan_gp: 0.213118 g: 0.231264 d: -10.349887 speed: 0.00 batches/s 
2023-11-17 14:53:33,662 INFO Iter: [11/300] l1: 0.065190 ae: 0.202627 wgan_g: -106.849434 wgan_d: -12.291664 wgan_gp: 0.232313 g: 0.214530 d: -9.968537 speed: 0.00 batches/s 
2023-11-17 14:57:40,433 INFO Iter: [12/300] l1: 0.064401 ae: 0.197289 wgan_g: -92.620567 wgan_d: -13.249625 wgan_gp: 0.261292 g: 0.221408 d: -10.636707 speed: 0.00 batches/s 
2023-11-17 15:01:51,469 INFO Iter: [13/300] l1: 0.062932 ae: 0.191844 wgan_g: -86.472458 wgan_d: -11.052431 wgan_gp: 0.186645 g: 0.219259 d: -9.185986 speed: 0.00 batches/s 
2023-11-17 15:12:23,330 INFO Iter: [14/300] l1: 0.060785 ae: 0.187085 wgan_g: -65.093498 wgan_d: -10.688768 wgan_gp: 0.160840 g: 0.232350 d: -9.080370 speed: 0.00 batches/s 
2023-11-17 15:28:29,681 INFO Iter: [15/300] l1: 0.061459 ae: 0.183699 wgan_g: -74.535896 wgan_d: -12.068075 wgan_gp: 0.184324 g: 0.219654 d: -10.224833 speed: 0.00 batches/s 
2023-11-17 15:41:08,972 INFO Iter: [16/300] l1: 0.061289 ae: 0.179535 wgan_g: -67.795830 wgan_d: -11.090837 wgan_gp: 0.177673 g: 0.221193 d: -9.314104 speed: 0.00 batches/s 
2023-11-17 15:50:42,704 INFO Iter: [17/300] l1: 0.059593 ae: 0.176907 wgan_g: -61.165020 wgan_d: -10.674706 wgan_gp: 0.155432 g: 0.222634 d: -9.120390 speed: 0.00 batches/s 
2023-11-17 15:58:19,454 INFO Iter: [18/300] l1: 0.060757 ae: 0.173439 wgan_g: -74.541710 wgan_d: -9.397870 wgan_gp: 0.147582 g: 0.206493 d: -7.922048 speed: 0.00 batches/s 
2023-11-17 16:05:53,431 INFO Iter: [19/300] l1: 0.061142 ae: 0.170886 wgan_g: -71.035667 wgan_d: -9.521272 wgan_gp: 0.143257 g: 0.207399 d: -8.088701 speed: 0.00 batches/s 
2023-11-17 16:12:20,189 ERROR Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/users/ug21/nikbiradar/.local/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 61, in _worker
    output = module(*input, **kwargs)
  File "/users/ug21/nikbiradar/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/users/ug21/nikbiradar/Image-Inpainting/sabhya/trainer.py", line 61, in forward
    global_penalty = self.calc_gradient_penalty(self.globalD, ground_truth, x2_inpaint.detach())
  File "/users/ug21/nikbiradar/Image-Inpainting/sabhya/trainer.py", line 110, in calc_gradient_penalty
    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,
  File "/users/ug21/nikbiradar/.local/lib/python3.9/site-packages/torch/autograd/__init__.py", line 234, in grad
    return Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 76.00 MiB (GPU 0; 47.54 GiB total capacity; 5.56 GiB already allocated; 84.75 MiB free; 5.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

