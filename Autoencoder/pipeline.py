# -*- coding: utf-8 -*-
"""pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p6iNluvgmxa3XMsbuiLZbf0IZx230JoP

#### System Setup
"""

import  numpy as np
import matplotlib.pyplot as plt
np.random.seed(42)
import torch
from torch.utils.data import TensorDataset, DataLoader
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import pandas as pd
import os, cv2, random

torch.backends.cudnn.benchmark = False
torch.backends.cudnn.deterministic = True
# torch.use_deterministic_algorithms(True, warn_only=True)

os.environ["CUBLAS_WORKSPACE_CONFIG"] = ":4096:8"

out_file = open("out.txt", "w")

torch.manual_seed(40)
torch.cuda.manual_seed_all(40)

if torch.cuda.is_available():
    device = 'cuda'
else:
    device = 'cpu'

out_file.write(device+"\n", flush = True)

def read_image_tensor(image_folder,transform):
    torch.cuda.empty_cache()
    all_images = []
    for images in os.listdir(image_folder):
        # for images in os.listdir(os.path.join(image_folder,subdir)):
        img = torchvision.io.read_image(os.path.join(image_folder,images)).float()
        all_images.append(transform(img))
        # out_file.write(f"Done with {subdir}\n")
    print(f"Done with Animals")
    return torch.stack(all_images).to(device)


def get_mask():
    mask = np.zeros((128,128,3),dtype=np.float32)
    mask[32:96,32:96,:]=255
    # out_file.write("mask",mask)
    # cv2.imwrite("mask.png",mask)
    return mask

def generate(img):

    min_num_spots, max_num_spots = 5, 8
    min_spot_size, max_spot_size = 10, 25
    black_img = np.zeros(img.shape)
    for _ in range(random.randint(min_num_spots, max_num_spots)):
        spot_size = random.randint(min_spot_size, max_spot_size)
        spot_x = random.randint(0, 256 - spot_size)
        spot_y = random.randint(0, 256 - spot_size)
        color = (255, 255, 255)  # White color in RGB format
        if random.choice([0,1]) == 1:
            # rectangle
            black_img[spot_y:spot_y + spot_size, spot_x:spot_x + spot_size] = color
            img[spot_y:spot_y + spot_size, spot_x:spot_x + spot_size] = color
        else:
            # circle
            cv2.circle(black_img, (spot_x, spot_y), spot_size, color, thickness=-1)
            cv2.circle(img, (spot_x, spot_y), spot_size, color, thickness=-1)

    return img,black_img

def make_input(labels):
    # apply generate input_image function on each image in labels and return the tensor of it
    images=[]

    mask = get_mask()
    mask[mask==255]=1
    for label in labels:
        img=np.array(label.cpu().permute(1,2,0).int())
        img = cv2.resize(img, (128, 128))
        # gen_img,mask= generate(img)
        gen_img = img*(1-mask)
        gen_img[gen_img==0]=255
        gen_img = np.array(torch.tensor(gen_img).cpu().permute(2,0,1).float())
        # masks.append(mask)
        images.append(gen_img)
    # out_file.write("mask",mask.shape)
    mask[mask==1]=255
    mask = np.array(torch.tensor(mask).cpu().permute(2,0,1).float())
    # out_file.write("img",images[0].shape)

    return torch.tensor(np.array(images)).to(device),torch.tensor(mask).to(device)

img_size = (128,128)
base_transform = transforms.Compose(
    [transforms.Resize(img_size)
    ]
)

dataset = read_image_tensor("../animals", base_transform)
out_file.write(f"{dataset.shape}\n", flush=True)

train_ratio = 0.8
train_set, test_set = torch.utils.data.random_split(dataset, [int(train_ratio*len(dataset)), len(dataset)-int(train_ratio*len(dataset))])

out_file.write(f"{len(train_set)}\n", flush=True)
out_file.write(f"{len(test_set)}\n",flush =True)

train_loader = torch.utils.data.DataLoader(dataset=train_set,
                                           batch_size=32,
                                           shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_set,
                                          batch_size=32,
                                          shuffle=False)

tensor_on_gpu = dataset[100]

# Move the tensor to the CPU
tensor_on_cpu = tensor_on_gpu.cpu()

plt.imshow(tensor_on_cpu.permute(1,2,0).int())

from models import *

model = AutoEncoder(in_channels=3, out_channels=3)
model.to(device)

def train_model(model, loss_fn, optimizer, num_epochs, train_loader, test_loader):
    train_losses=[]
    # test_losses=[]
    prev_test_loss=1000000

    for epoch in range(num_epochs):
        l=[]
        for data in train_loader:
            img = data
            img = img.to(device)
            optimizer.zero_grad()
            transformed_img,mask = make_input(img)
            transformed_img = transformed_img.float()
            mask = mask.float()
            output= model(transformed_img,mask)
            loss = loss_fn(output, img)
            l.append(loss.item())
            loss.backward()
            optimizer.step()
        # if (epoch+1) % 5== 0:
        torch.save(model, f'lastmodel.pth')
        # if avg_test_loss<=prev_test_loss:
        #     prev_test_loss=avg_test_loss
        #     torch.save(model, f'bestmodel.pth')
        avg_train_loss=sum(l)/len(l)
        train_losses.append(avg_train_loss)
        out_file.write('Epoch [{}/{}], Loss: {:.4f}\n'.format(epoch+1, num_epochs, avg_train_loss), flush = True)
        print('Epoch [{}/{}], Loss: {:.4f}\n'.format(epoch+1, num_epochs, avg_train_loss))

    
    return train_losses

loss = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)
epochs = 2000

train_losses=train_model(model, loss, optimizer, epochs, train_loader, test_loader)
# out_file.write(f'test_loss: {test_losses}\n', flush = True)
out_file.write(f'train_loss: {train_losses}\n', flush = True)


# Save the model checkpoint
# torch.save(model.state_dict(), 'model.ckpt')

# Load the model checkpoint
# model.load_state_dict(torch.load('model_epoc34.pth'))
model = torch.load('lastmodel.pth')

with torch.no_grad():
    losses = []
    for data in test_loader:
        data = data.to(device)
        # out_file.write(data.shape)
        # data = data.cpu().numpy().transpose((1, 2, 0))
        data,mask = make_input(data)

        recon = model(data,mask)
        losses.append(nn.MSELoss()(recon, data).item())
    out_file.write(f"Average Test Reconstruction Loss: {sum(losses)/len(losses)}\n", flush = True)

data,mask = make_input(data)
# plt.imshow()
fig, ax = plt.subplots(2, 4, figsize=(15, 7))

for i in range(4):

    ax[0, i].imshow(data[i].int().cpu().numpy().transpose((1, 2, 0)))
    ax[1, i].imshow(recon[i].int().cpu().numpy().transpose((1, 2, 0)))
    ax[0, i].axis('OFF')
    ax[1, i].axis('OFF')
plt.show()
plt.savefig("LASTOUTPUT.png")
plt.clf()

x=list(range(1,epochs+1))

plt.plot(x, train_losses, label='Train Losses', color='blue')

# # Plot the second line
# plt.plot(x, test_losses, label='Test Losses', color='green')

plt.savefig("losses.png")

