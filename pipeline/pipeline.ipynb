{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82476c3",
      "metadata": {
        "id": "f82476c3"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/home/sachi/.pyenv/versions/3.8.10/bin/python' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/home/sachi/.pyenv/versions/3.8.10/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7geIp0evzEfr",
      "metadata": {
        "id": "7geIp0evzEfr"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "torch.manual_seed(40)\n",
        "torch.cuda.manual_seed_all(40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8TyKKrtvq7An",
      "metadata": {
        "id": "8TyKKrtvq7An"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "mSV3BkYgtLoo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mSV3BkYgtLoo",
        "outputId": "58b9bde8-c9bf-4e30-c984-f51fead04a4b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8e610d1d",
      "metadata": {
        "id": "8e610d1d"
      },
      "outputs": [],
      "source": [
        "def read_image_tensor(image_folder,transform,num_images=None):\n",
        "    if num_images==None:\n",
        "        num_images = len(os.listdir(image_folder))\n",
        "    images = []\n",
        "    for i in range(num_images):\n",
        "        img = torchvision.io.read_image(os.path.join(image_folder,f\"{i}.jpg\")).float()\n",
        "        images.append(transform(img))\n",
        "    return torch.stack(images).to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "451ab492",
      "metadata": {
        "id": "451ab492"
      },
      "outputs": [],
      "source": [
        "def get_labels(csv_file):\n",
        "    # TODO: Return a torch tensor after reading the labels in csv_file. Convert to float().\n",
        "    labels = pd.read_csv(csv_file)[\"label\"].values\n",
        "    return torch.tensor(labels).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "673f056d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "673f056d",
        "outputId": "76e37253-82f1-4c80-ff32-056319363344"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "img_size = (256,256)\n",
        "base_transform = transforms.Compose(\n",
        "    [transforms.Resize(img_size)\n",
        "    ]\n",
        ")\n",
        "train_X = read_image_tensor(\"../animals/train/\",base_transform)/256\n",
        "train_Y = get_labels(\"../animals/train.csv\")\n",
        "test_X = read_image_tensor(\"../animals/test/\",base_transform)/256\n",
        "test_Y = get_labels(\"../animals/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7MjgNtZbqBDb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MjgNtZbqBDb",
        "outputId": "f3179a89-972d-4829-da98-b1ca0b014a2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1000, 3, 256, 256])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6989c64f",
      "metadata": {
        "id": "6989c64f"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, test_loader, num_epochs, loss_function, optimizer):\n",
        "    # TODO: Make sure you read through these lines of code and understand all key lines.\n",
        "    # For example: Why do you need to zero out the gradients using optimizer.zero_grad() in the for loop?\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for i, data in enumerate(train_loader):\n",
        "            inputs,labels = data\n",
        "            optimizer.zero_grad()\n",
        "            output = model(inputs)\n",
        "            loss = loss_function(output,labels.view(output.shape))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        average_loss = total_loss/len(train_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                inputs, labels = data\n",
        "                outputs = model(inputs)\n",
        "                pred = (outputs > 0.5)*1\n",
        "                correct += (pred==labels.view(pred.shape)).sum()\n",
        "                total += labels.size(0)\n",
        "            accur = 100*correct/total\n",
        "            print(f\"Test Accuracy after Epoch {epoch+1}: {accur:.2f}%\")\n",
        "\n",
        "    print(\"Training done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "595b0797",
      "metadata": {
        "id": "595b0797"
      },
      "outputs": [],
      "source": [
        "# PART 1: TODO\n",
        "# Write down the model description\n",
        "# model = ...\n",
        "# Relevant torch.nn classes you will need include nn.Sequential, nn.Conv2d, nn.MaxPool2d and so on.\n",
        "from ../deep-learning/models import *\n",
        "\n",
        "model = UNet256()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "nxyq0aeXrdS_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxyq0aeXrdS_",
        "outputId": "f51fe5e3-87bb-4259-8739-ec80bb4c0484"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU()\n",
              "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (4): ReLU()\n",
              "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (6): Flatten(start_dim=1, end_dim=-1)\n",
              "  (7): Linear(in_features=131072, out_features=64, bias=True)\n",
              "  (8): ReLU()\n",
              "  (9): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (10): Sigmoid()\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "277e16b9",
      "metadata": {
        "id": "277e16b9"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(train_X.to(device), train_Y.to(device))\n",
        "test_dataset = TensorDataset(test_X.to(device), test_Y.to(device))\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "num_epochs = 30\n",
        "\n",
        "loss_func = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "55eb4495",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55eb4495",
        "outputId": "4b66a8a1-b5f7-4c28-b188-a3fb39f439a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30, Loss: 1.0351\n",
            "Test Accuracy after Epoch 1: 56.75%\n",
            "Epoch 2/30, Loss: 0.6895\n",
            "Test Accuracy after Epoch 2: 59.00%\n",
            "Epoch 3/30, Loss: 0.6794\n",
            "Test Accuracy after Epoch 3: 55.00%\n",
            "Epoch 4/30, Loss: 0.6650\n",
            "Test Accuracy after Epoch 4: 60.50%\n",
            "Epoch 5/30, Loss: 0.6242\n",
            "Test Accuracy after Epoch 5: 63.25%\n",
            "Epoch 6/30, Loss: 0.6178\n",
            "Test Accuracy after Epoch 6: 64.25%\n",
            "Epoch 7/30, Loss: 0.5659\n",
            "Test Accuracy after Epoch 7: 64.25%\n",
            "Epoch 8/30, Loss: 0.5127\n",
            "Test Accuracy after Epoch 8: 61.00%\n",
            "Epoch 9/30, Loss: 0.4695\n",
            "Test Accuracy after Epoch 9: 64.50%\n",
            "Epoch 10/30, Loss: 0.4035\n",
            "Test Accuracy after Epoch 10: 64.25%\n",
            "Epoch 11/30, Loss: 0.3353\n",
            "Test Accuracy after Epoch 11: 66.50%\n",
            "Epoch 12/30, Loss: 0.2727\n",
            "Test Accuracy after Epoch 12: 66.75%\n",
            "Epoch 13/30, Loss: 0.2427\n",
            "Test Accuracy after Epoch 13: 63.75%\n",
            "Epoch 14/30, Loss: 0.1707\n",
            "Test Accuracy after Epoch 14: 65.75%\n",
            "Epoch 15/30, Loss: 0.1147\n",
            "Test Accuracy after Epoch 15: 67.75%\n",
            "Epoch 16/30, Loss: 0.0859\n",
            "Test Accuracy after Epoch 16: 67.50%\n",
            "Epoch 17/30, Loss: 0.0570\n",
            "Test Accuracy after Epoch 17: 65.25%\n",
            "Epoch 18/30, Loss: 0.0554\n",
            "Test Accuracy after Epoch 18: 66.00%\n",
            "Epoch 19/30, Loss: 0.0365\n",
            "Test Accuracy after Epoch 19: 68.50%\n",
            "Epoch 20/30, Loss: 0.0216\n",
            "Test Accuracy after Epoch 20: 66.75%\n",
            "Epoch 21/30, Loss: 0.0142\n",
            "Test Accuracy after Epoch 21: 67.75%\n",
            "Epoch 22/30, Loss: 0.0097\n",
            "Test Accuracy after Epoch 22: 68.50%\n",
            "Epoch 23/30, Loss: 0.0076\n",
            "Test Accuracy after Epoch 23: 67.25%\n",
            "Epoch 24/30, Loss: 0.0062\n",
            "Test Accuracy after Epoch 24: 69.25%\n",
            "Epoch 25/30, Loss: 0.0051\n",
            "Test Accuracy after Epoch 25: 68.25%\n",
            "Epoch 26/30, Loss: 0.0043\n",
            "Test Accuracy after Epoch 26: 68.25%\n",
            "Epoch 27/30, Loss: 0.0036\n",
            "Test Accuracy after Epoch 27: 68.00%\n",
            "Epoch 28/30, Loss: 0.0031\n",
            "Test Accuracy after Epoch 28: 68.25%\n",
            "Epoch 29/30, Loss: 0.0028\n",
            "Test Accuracy after Epoch 29: 67.75%\n",
            "Epoch 30/30, Loss: 0.0025\n",
            "Test Accuracy after Epoch 30: 69.00%\n",
            "Training done.\n"
          ]
        }
      ],
      "source": [
        "train_model(model,train_loader,test_loader,num_epochs,loss_func,optimizer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
