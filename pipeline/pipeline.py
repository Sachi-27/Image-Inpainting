# -*- coding: utf-8 -*-
"""pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p6iNluvgmxa3XMsbuiLZbf0IZx230JoP

#### System Setup
"""

import torch
from torch.utils.data import TensorDataset, DataLoader
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import pandas as pd
import os

torch.backends.cudnn.benchmark = False
torch.backends.cudnn.deterministic = True
torch.use_deterministic_algorithms(True, warn_only=True)

os.environ["CUBLAS_WORKSPACE_CONFIG"] = ":4096:8"

torch.manual_seed(40)
torch.cuda.manual_seed_all(40)

if torch.cuda.is_available():
    device = 'cuda'
else:
    device = 'cpu'

device

def read_image_tensor(image_folder,transform):
    all_images = []
    for subdir in os.listdir(image_folder)[:10]:
        for images in os.listdir(os.path.join(image_folder,subdir)):
            img = torchvision.io.read_image(os.path.join(image_folder,subdir,images)).float()
            all_images.append(transform(img))
        print(f"Done with {subdir}")
    return torch.stack(all_images).to(device)

import os, cv2, random
def generate(img):
    # SIRF algorithm to detect key points in the image
    # print(img.shape)
    # plt.imshow(img)
    # features = cv2.SIFT_create()
    # keypoints = features.detect(img, None)
    # # Choose top 50 and bottom 50 keypoints
    # keypoints1 = sorted(keypoints, key=lambda x: -x.response)[:min(50, len(keypoints))]
    # keypoints2 = sorted(keypoints, key=lambda x: x.response)[:min(50, len(keypoints))]
    # # Randomly choose 3 keypoints from each set
    # keypoints1 = random.sample(keypoints1, 3)
    # keypoints2 = random.sample(keypoints2, 3)

    # # between every two keypoints draw a line
    # for i in range(len(keypoints1)):
    #     for j in range(len(keypoints2)):
    #         x1, y1 = keypoints1[i].pt
    #         x2, y2 = keypoints2[j].pt
    #         x1 = int(x1)
    #         y1 = int(y1)
    #         x2 = int(x2)
    #         y2 = int(y2)
    #         cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), random.randint(1,8))


    ####
    # Add random white spots to the image
    # show the image
    min_num_spots, max_num_spots = 5, 8
    min_spot_size, max_spot_size = 10, 25
    for _ in range(random.randint(min_num_spots, max_num_spots)):
        spot_size = random.randint(min_spot_size, max_spot_size)
        spot_x = random.randint(0, 256 - spot_size)
        spot_y = random.randint(0, 256 - spot_size)
        color = (255, 255, 255)  # White color in RGB format
        if random.choice([0,1]) == 1:
            # rectangle
            img[spot_y:spot_y + spot_size, spot_x:spot_x + spot_size] = color
        else:
            # circle
            cv2.circle(img, (spot_x, spot_y), spot_size, color, thickness=-1)

    return img

def make_input(labels):
    # apply generate input_image function on each image in labels and return the tensor of it
    images=[]
    for label in labels:
        img=np.array(label.permute(1,2,0).int())
        img = cv2.resize(img, (128, 128))
        gen_img= generate(img)
        gen_img = np.array(torch.tensor(gen_img).permute(2,0,1).float())
        images.append(gen_img)

    return torch.tensor(images).to(device)

img_size = (128,128)
base_transform = transforms.Compose(
    [transforms.Resize(img_size)
    ]
)

dataset = read_image_tensor("../animals/animals", base_transform)
dataset.shape

import matplotlib.pyplot as plt
import  numpy as np
train_ratio = 0.8
train_set, test_set = torch.utils.data.random_split(dataset, [int(train_ratio*len(dataset)), len(dataset)-int(train_ratio*len(dataset))])

print(len(train_set))
print(len(test_set))

train_loader = torch.utils.data.DataLoader(dataset=train_set,
                                           batch_size=32,
                                           shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=test_set,
                                          batch_size=32,
                                          shuffle=False)

plt.imshow(dataset[100].permute(1,2,0).int())

from models import *

model = AutoEncoder(in_channels=3, out_channels=3)
model.to(device)

def train_model(model, loss_fn, optimizer, num_epochs, train_loader, test_loader):
  for epoch in range(num_epochs):
      for data in train_loader:
          img = data
          img = img.to(device)
          optimizer.zero_grad()
          transformed_img = make_input(img).float()
          output= model(transformed_img)
          loss = loss_fn(output, img)
          loss.backward()
          optimizer.step()
    #   if (epoch+1) % 5== 0:
      print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))

loss = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.005)
epochs = 20

train_model(model, loss, optimizer, epochs, train_loader, test_loader)

# Save the model checkpoint
torch.save(model.state_dict(), 'model.ckpt')

# Load the model checkpoint
model.load_state_dict(torch.load('model.ckpt'))

with torch.no_grad():
    losses = []
    for data in test_loader:
        data = data.to(device)
        recon = model(data)
        losses.append(nn.MSELoss()(recon, data).item())
    print(f"Average Test Reconstruction Loss: {sum(losses)/len(losses)}")

fig, ax = plt.subplots(2, 7, figsize=(15, 4))
for i in range(7):
    ax[0, i].imshow(data[i].int().cpu().numpy().transpose((1, 2, 0)))
    ax[1, i].imshow(recon[i].int().cpu().numpy().transpose((1, 2, 0)))
    ax[0, i].axis('OFF')
    ax[1, i].axis('OFF')
plt.show()